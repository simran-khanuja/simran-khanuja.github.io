<!doctype html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q759EBKEQ5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-Q759EBKEQ5');
    </script>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Pre-Doctoral Researcher, Google Research India">
    <meta name="author" content="Simran Khanuja">
    <meta name="theme-color" content="#222222">

    <link rel="apple-touch-icon" sizes="180x180" href="images/nicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/nicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/nicons/favicon-16x16.png">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
        integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/style-2.css">

    <title>Simran Khanuja</title>
</head>

<body>
    <!-- <h1>Hello, world!</h1> -->
    <div class="container pt-5 allstuffp">
        <div class="row pt-5 allstuff">
            <div class="col-md-4 pt-5">
                <div class="fixed-posi">
                    <p class="name">Simran Khanuja</p>
                    <img src="images/profile.png" class="profilepic pt-1 pb-2">
                    <div class="pt-5 menur"><a class="menulink" target="_blank" href="assets/cv_jan25.pdf">curriculum
                            vitae</a></div>
                    <div class=""><a class="menulink" target="_blank"
                            href="https://scholar.google.com/citations?user=yInhszwAAAAJ&hl=en">google scholar</a></div>
                    <div class=""><a class="menulink" target="_blank" href="assets/bio.html">third-person bio</a></div>
                    <div class=""><a class="menulink" target="_blank"
                            href="assets/sop_cmu.pdf">statement of purpose</a></div>
                    <div class=""><a class="menulink" target="_blank" href="mailto:khanuja.simran7@gmail.com">email
                            address</a></div>
                    <div class=""><a class="menulink" target="_blank" href="https://github.com/simran-khanuja">github
                            profile</a></div>
                    <div class=""><a class="menulink" target="_blank"
                            href="https://www.linkedin.com/in/simran-khanuja-6b80b6144/?originalSubdomain=in">linkedin</a>
                    </div>
                    <div class=""><a class="menulink" target="_blank"
                            href="https://twitter.com/simi_97k?lang=en">twitter</a></div>


                    <!-- <div class="pt-5">usercontext</div> -->
                    <!-- <div class="">travel history</div> -->
                    <!-- <div class="">this template</div> -->
                </div>
            </div>
            <div class="col-md-8 pt-5 about">
                Hi! I am a third-year PhD student at the <a class="in-text" href="https://www.lti.cs.cmu.edu/"
                    target="_blank">Language Technologies Institute</a> at Carnegie Mellon University. I am advised by
                <a class="in-text" href="http://www.phontron.com/" target="_blank">Graham Neubig</a> and have
                wonderful friends and collaborators at <a class="in-text" href="https://www.cs.cmu.edu/~neulab/"
                    target="_blank">Neulab</a> :) <br> <br>

                These days, I have been working on analysing the cultural capabilities of vision-language models. In particular, I'm revisiting the age old problem of translation, and exploring how it extends to multiple modalities including images and videos. Checkout this <a class="in-text"
                href="https://github.com/simran-khanuja/awesome-cultural-nlp"
                target="_blank">github repo</a> where I've been collecting resources for cultural NLP and please feel free to send a PR to add relevant material! <br> <br>

                We also won a <a class="in-text"
                href="https://2024.emnlp.org/program/best_papers/"
                target="_blank">best paper</a> award at EMNLP 2024 for our work on image transcreation, where we introduce the task of localizing images using machine learning systems! I'm a mentor at OpenNLP Labs where we are doing cool projects related to this :) Check out their initiatives <a class="in-text"
                href="https://opennlplabs.org/"
                target="_blank">here</a>. I've been working on several aspects of this problem in my research, including data curation, automatic evaluation and modeling. If anyone is interested to chat about it, please feel free to reach out on my email :) <br> <br>

                I'm looking for summer 2025 internships on topics around geo-cultural diversity for vision-language models! Please reach out to me on my <a class="in-text"
                href="mailto:skhanuja@andrew.cmu.edu">email</a> if I might be a good fit! <br> <br>
                

                Previously, I've had the good fortune to research multilingualism and low-resource NLP, especially for Indian languages, at <a class="in-text" href="https://research.google/teams/india-research-lab/"
                target="_blank">Google Research India</a> (GRI) and <a class="in-text"
                href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/"
                target="_blank">Microsoft Research India</a> (MSR-I). I'm so grateful to have worked with brilliant researchers whose mentorship has been critical to my growth as a researcher: <a class="in-text" href="http://www.phontron.com/" target="_blank">Graham Neubig</a> (CMU), <a class="in-text" href="https://parthatalukdar.github.io/"
                target="_blank">Partha Talukdar</a> (GRI), <a class="in-text" href="https://www.ruder.io/"
                target="_blank">Sebastian Ruder</a> (GRI), <a class="in-text" href="https://scholar.google.fr/citations?user=45KfCpgAAAAJ&hl=fr"
                target="_blank">Alexis Conneau</a> (GRI), <a class="in-text"
                href="https://www.microsoft.com/en-us/research/people/susitara/" target="_blank">Sunayana
                Sitaram</a> (MSR-I), <a class="in-text" href="https://mbzuai.ac.ae/study/faculty/monojit-choudhury/"
                target="_blank">Monojit Choudhury</a> (MSR-I), <a
                class="in-text" href="https://und.edu/directory/s.vidhyadharan#researchint" target="_blank">Dr.
                Sreejith V</a> (BITS-G).  <br> <br>   

                Apart from spending my time doing fun research, I hold a keen interest in music, a
                passion I got to pursue as part of the <a class="in-text"
                    href="https://www.youtube.com/channel/UCs3URAnJc629Is22Q6tPK4g" target="_blank">Music Society</a> at
                BITS, where I gave performances as a vocalist. <br><br>

                For more information, you can check out my CV <a class="in-text" href="assets/cv.pdf"
                    target="_blank">here</a> or reach out to me on my <a class="in-text"
                    href="mailto:skhanuja@andrew.cmu.edu">email</a> :)

                <!-- Previously, I was a <a class="in-text" href="https://research.google/people/SimranKhanuja/"
                    target="_blank">Pre-Doctoral
                    Researcher</a> at <a class="in-text" href="https://research.google/teams/india-research-lab/"
                    target="_blank">Google Research India</a>,
                working in the <a class="in-text"
                    href="https://research.google/research-areas/natural-language-processing/" target="_blank">Natural
                    Language Understanding</a> team, mentored by <a class="in-text" href="http://talukdar.net/"
                    target="_blank">Dr. Partha Talukdar</a>. At Google, I researched multilinguality for low [text]
                resource languages and explored leveraging multimodal signals for the same. I applied my research
                to improve neural semantic parsing for eight Indian languages, for the Google Assistant. <br> <br>

                I have had the good fortune to complete my bachelor thesis at <a class="in-text"
                    href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/"
                    target="_blank">Microsoft Research India</a> where I was advised by <a class="in-text"
                    href="https://www.microsoft.com/en-us/research/people/susitara/" target="_blank">Dr. Sunayana
                    Sitaram</a> and <a class="in-text" href="https://www.microsoft.com/en-us/research/people/monojitc/"
                    target="_blank">Dr. Monojit Choudhury</a>. I have also spent some wonderful summers interning at the
                <a class="in-text" href="https://ltrc.iiit.ac.in/" target="_blank">MT-NLP Lab, IIIT Hyderabad</a> with
                <a class="in-text" href="https://faculty.iiit.ac.in/~dipti/" target="_blank">Dr. Dipti Misra Sharma</a>
                and Liveweaver, Pune. <br><br> -->

                <!-- My research experiences have given me a unique opportunity to contribute towards developing technologies
                for the <a class="in-text" href="https://youtu.be/MpPJ4Rr-5SQ" target="_blank">linguistically rich</a>
                and diverse set of Indian languages, for which I am ever grateful. I aspire to make fundamental changes to real-world applications, to foster cultural equity and inclusivity. <br><br> -->

                <!-- I graduated with a B.E. (Hons.) in Computer Science and a MSc. (Hons.) in Economics from <a
                    class="in-text" href="https://www.bits-pilani.ac.in/" target="_blank">BITS Pilani</a>, Goa, India in
                2020. During my time there, I worked on multimodal emotion recognition in healthcare with <a
                    class="in-text" href="https://und.edu/directory/s.vidhyadharan#researchint" target="_blank">Dr.
                    Sreejith V</a>.  -->

                <p class="header pt-5">Updates</p>
                <div style="height:250px;overflow:auto;">
                    <table>
                        <col width="100px">
                        <tr>
                            <td><b>Jan 2025:</b></td>
                            <td>Our paper on <a href="https://arxiv.org/abs/2412.13717">designing automatic evaluation metrics</a> for image transcreation is accepted at NAACL 2025 (code release soon)!</td>
                        </tr>
                        <tr>
                            <td><b>Jan 2025:</b></td>
                            <td><a href="https://neulab.github.io/Pangea/">Pangea</a> is accepted at ICLR 2025!</td>
                        </tr>
                        <tr>
                            <td><b>Dec 2024:</b></td>
                            <td>We won best paper runner-up for our work on building an image-editing platform for localization at IEEE Big Data 2024! Pre-print out soon :)</td>
                        </tr>
                        <tr>
                            <td><b>Nov 2024:</b></td>
                            <td>We won <a class="in-text"
                                href="https://2024.emnlp.org/program/best_papers/"
                                target="_blank">best paper</a> for our work on image transcreation at EMNLP 2024! Very honored and humbled :')</td>
                        </tr>
                        <tr>
                            <td><b>Oct 2024:</b></td>
                            <td>We recently released <a href="https://neulab.github.io/Pangea/">Pangea-7B</a>, an open-sourced multi-(lingual, modal, cultural) model!</td>
                        </tr>
                        <tr>
                            <td><b>Sept 2024:</b></td>
                            <td>Our paper on <a href="https://arxiv.org/pdf/2404.01247.pdf">image transcreation</a> accepted at EMNLP (Main) '24 (<a href="https://x.com/simi_97k/status/1838319675480080532">tweet thread</a>)!</td>
                        </tr>
                        <tr>
                            <td><b>Sept 2024:</b></td>
                            <td>Invited talk on image transcreation at Pinterest!</td>
                        </tr>
                        <tr>
                            <td><b>June 2024:</b></td>
                            <td>Invited keynote at the <a href="https://turing.iimas.unam.mx/americasnlp/2024_workshop.html">AmericasNLP workshop</a> at NAACL '24! (<a href="https://t.co/WKxWOEGuXn">slides</a>, <a href="https://youtu.be/TuDu-n82Uus">recording</a>)</td>
                        </tr>
                        <tr>
                            <td><b>May 2024:</b></td>
                            <td><a href="https://opennlplabs.org/About-Us">Mentor</a> for OpenNLP Labs where we are building technology to support cultural translation of stories for <a href="https://opennlplabs.org/EduLang">EduLang!</a></td>
                        </tr>
                        <tr>
                            <td><b>Apr 2024:</b></td>
                            <td>Grateful to be supported by the <a href="https://www.cs.cmu.edu/funds/endowed-funds">Waibel Presidential Fellowship</a> for 2024-25!</td>
                        </tr>
                        <tr>
                            <td><b>Mar 2024:</b></td>
                            <td>Gave a talk on <a href="https://arxiv.org/pdf/2404.01247.pdf">image transcreation</a> at University of Edinburgh!</td>
                        </tr>
                        <tr>
                            <td><b>Mar 2024:</b></td>
                            <td>Our work on <a href="https://arxiv.org/abs/2311.06379">data-efficient multilingual learning</a> to appear in NAACL 2024! Reach out if you'd like to catch up in Mexico City :)</td>
                        </tr>
                        <tr>
                            <td><b>Jan 2024:</b></td>
                            <td>Gave a talk on image transcreation (<a href="https://arxiv.org/pdf/2404.01247.pdf">preprint</a>, <a href="assets/image_transcreation_slides.pdf">slides</a>) at Google Research, Microsoft Research, IISc and Microsoft IDC!</td>
                        </tr>
                        <tr>
                            <td><b>Dec 2023:</b></td>
                            <td>Gave a lecture at CMU 11737 (Multilingual NLP) on Image-Text Modeling for Multilingual NLP! (<a class="in-text" href="assets/lecture-image_text.pdf"
                                target="_blank">link to slides</a>, <a class="in-text" href="https://twitter.com/simi_97k/status/1734347845787111511"
                                target="_blank">tweet thread</a>) </td>
                        </tr>
                        <tr>
                            <td><b>Aug 2023:</b></td>
                            <td>Organized (and won a best paper at!) the <a href="https://www.lti.cs.cmu.edu/SRS-2023">Student Research Symposium</a> at CMU LTI </td>
                        </tr>
                        <tr>
                            <td><b>May 2023:</b></td>
                            <td>Our work on <a href="https://arxiv.org/abs/2305.16171">multi-cultural figurative language</a> to appear in ACL 2023 Findings! We will be presenting at the LAW workshop :)</td>
                        </tr>
                        <tr>
                            <td><b>May 2023:</b></td>
                            <td>I will be attending EACL 2023 in-person to present <a href="https://arxiv.org/abs/2205.12676">our work</a> at SIGTYP and C3NLP!</td>
                        </tr>
                        <tr>
                            <td><b>Jan 2023:</b></td>
                            <td>Honored to receive the best paper award for <a href="https://arxiv.org/pdf/2205.12446.pdf">FLEURS</a> at SLT 2022!</td>
                        </tr>
                        <tr>
                            <td><b>Aug 2022:</b></td>
                            <td>I started my PhD at CMU, LTI!</td>
                        </tr>
                        <tr>
                            <td><b>Aug 2022:</b></td>
                            <td>I presented our research and its application to Google Assistant at the <a href="https://rsvp.withgoogle.com/events/decode-with-google-2022">Decode with Google 2022</a> event! Thanks to my amazing team at <a href="https://research.google/teams/india-research-lab/">Google Research India</a> for the opportunity!</td>
                        </tr>
                        <tr>
                            <td><b>Oct 2021:</b></td>
                            <td>I'll be attending <a href="http://lig-alps.imag.fr/">ALPS 2022</a>! Feel free to get in
                                touch if you'll be attending the same.</td>
                        </tr>
                        <tr>
                            <td><b>Aug 2021:</b></td>
                            <td>Conducting a hands-on TensorFlow Tutorial session at the <a
                                    href="http://cvit.iiit.ac.in/summerschool2021/program.php">5th CVIT IIIT Summer
                                    School!</a></td>
                        </tr>
                        <tr>
                            <td><b>Aug 2021:</b></td>
                            <td>Hosting the NLP networking session at IKDD 2021 where <a
                                    href="https://www.microsoft.com/en-us/research/people/monojitc/">Dr. Monojit
                                    Choudhury</a> is our guest speaker!</td>
                        </tr>
                        <tr>
                            <td><b>May 2021:</b></td>
                            <td>Our work on merging multiple pre-trained LMs to appear in ACL 2021 Findings.</td>
                        </tr>
                        <tr>
                            <td><b>Mar 2021:</b></td>
                            <td>Technical write-up on MuRIL is now available on <a
                                    href="https://arxiv.org/pdf/2103.10730.pdf">arxiv</a>.</td>
                        </tr>
                        <tr>
                            <td><b>Mar 2021:</b></td>
                            <td>The pre-trained MuRIL model (with MLM) is now available on <a
                                    href="https://huggingface.co/google/muril-base-cased">HuggingFace</a>.</td>
                        </tr>
                        <tr>
                            <td><b>Nov 2020:</b></td>
                            <td><a href="https://tfhub.dev/google/MuRIL/1">Open-sourced</a> a multilingual model for
                                Indian languages named MuRIL on TFHub!</td>
                        </tr>
                        <tr>
                            <td><b>Sep 2020:</b></td>
                            <td>Hosted a Fireside Chat with Jeff Dean on his virtual Google India visit!</td>
                        </tr>
                        <tr>
                            <td><b>Aug 2020:</b></td>
                            <td>I am joining the <a href="https://research.google/locations/india/">Google Research
                                    India</a> lab as a Pre-Doctoral Researcher where I am working with <a
                                    href="http://talukdar.net/">Dr. Partha Talukdar!</a></td>
                        </tr>
                        <tr>
                            <td><b>Aug 2020:</b></td>
                            <td>Graduated from <a href="https://www.bits-pilani.ac.in/">BITS Pilani</a> Goa with a dual
                                degree in Computer Science and Economics.</td>
                        </tr>
                        <tr>
                            <td><b>July 2020:</b></td>
                            <td>The GLUECoS <a href="https://github.com/microsoft/GLUECoS">code</a> and leaderboard <a
                                    href="https://microsoft.github.io/GLUECoS/">website</a> are now open-sourced!</td>
                        </tr>
                        <tr>
                            <td><b>Apr 2020:</b></td>
                            <td><a href="https://arxiv.org/abs/2004.12376">Paper</a> on building a benchmark for
                                code-switched language processing to appear at ACL 2020! (<a
                                    href="https://slideslive.com/38928983/gluecos-an-evaluation-benchmark-for-codeswitched-nlp">Talk</a>)
                            </td>
                        </tr>
                        <tr>
                            <td><b>Mar 2020:</b></td>
                            <td>We created a <a href="https://www.cse.iitb.ac.in/~pjyothi/indiccorpora/#nli">new
                                    dataset</a> for code-mixed conversational NLI! <a
                                    href="https://arxiv.org/abs/2004.05051">Paper</a> to appear in CALCS, LREC 2020.
                            </td>
                        </tr>
                        <tr>
                            <td><b>Jul 2019:</b></td>
                            <td>I am doing my bachelor thesis at the <a
                                    href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft
                                    Research India</a> lab, where I am working with <a
                                    href="https://www.microsoft.com/en-us/research/people/susitara/">Dr. Sunayana
                                    Sitaram</a>!</td>
                        </tr>
                        <tr>
                            <td><b>Jun 2019:</b></td>
                            <td><a href="https://www.aclweb.org/anthology/W19-7810.pdf">Work</a> done on generating
                                code-mixed text in summer 2018 to appear at TLT SyntaxFest 2019</td>
                        </tr>
                        <tr>
                            <td><b>Apr 2018:</b></td>
                            <td>Summer internship at the <a href="https://ltrc.iiit.ac.in/">MT-NLP lab</a>, IIIT
                                Hyderabad where I will be working with <a
                                    href="https://www.iiit.ac.in/people/faculty/dipti/">Dr. Dipti Misra Sharma</a></td>
                        </tr>
                    </table>
                </div>

                <p class="header pt-5">Publications</p>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Towards Automatic Evaluation for Image Transcreation
                        </span><br>
                        <span class="thisauthor">Simran Khanuja</span><sup>*</sup>, Vivek Iyer<sup>*</sup>, Claire He, Graham Neubig<br>
                        <span class="conf"> <a class="confshort" href="https://2025.naacl.org/">NAACL 2025</a> | 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics </span> <br>
                        <a class="tag" href="https://arxiv.org/abs/2412.13717" target="_blank">pdf</a><span
                        class="tagsep">|</span>
                        <a class="tag" href="cites/automatic.bib" target="_blank">cite</a>
                    </p>
                </div>

                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages
                        </span><br>
                        Xiang Yue<sup>*</sup>, Yueqi Song<sup>*</sup>, Akari Asai, Seungone Kim, Jean de Dieu Nyandwi, <span class="thisauthor">Simran Khanuja</span>, 
                        Anjali Kantharuban, Lintang Sutawika, Sathyanarayanan Ramamoorthy, Graham Neubig<br>
                        <span class="conf"> <a class="confshort" href="https://iclr.cc/">ICLR 2025</a> | International Conference on Learning Representations </span> <br>
                        <a class="tag" href="https://neulab.github.io/Pangea/" target="_blank">web</a><span class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/pdf/2410.16153.pdf" target="_blank">pdf</a><span
                        class="tagsep">|</span>
                        <a class="tag" href="cites/pangea.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="badge badge-sp"> 🏆 Best Paper Runner-Up </span><br><span class="papertitle">HILITE: Human-in-the-loop Interactive Tool for Image Editing</span><br>
                        Arya Pasumarthi, Armaan Sharma, Jainish H. Patel, ..., Diyi Yang, Graham Neubig, <span class="thisauthor">Simran Khanuja</span><br>
                        <span class="conf"><a class="confshort" href="https://studentpapers-bigdata2024.netlify.app/">IEEE BigData 2024</a> |
                            2024 IEEE International Conference on Big Data (Undergraduate Symposium)</span><br>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="badge badge-sp"> 🏆 Best Paper </span><br><span class="papertitle"><em>An image speaks a thousand words, but can everyone listen?</em><br> On translating images for cultural relevance
                        </span><br>
                       <span class="thisauthor">Simran Khanuja</span>, Sathyanarayanan Ramamoorthy, Yueqi Song, Graham Neubig<br>
                       <span class="conf"><a class="confshort" href="https://2024.naacl.org/">EMNLP '24</a> |
                        Conference on Empirical Methods in Natural Language Processing</span><br>
                        <a class="tag" href="https://machine-transcreation.github.io/image-transcreation/" target="_blank">web</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/pdf/2404.01247.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://github.com/simran-khanuja/image-transcreation" target="_blank">code</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/transcreation.bib" target="_blank">cite</a><span
                        class="tagsep">|</span>
                        <a class="tag" href="https://t.co/WKxWOEGuXn" target="_blank">slides</a><span
                        class="tagsep">|</span>
                        <a class="tag" href="https://youtu.be/oIAzzbN6yxY?feature=shared" target="_blank">video</a><span
                        class="tagsep">|</span>
                        <a class="tag" href="https://youtu.be/TuDu-n82Uus" target="_blank">NAACL Talk</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">DeMuX: Data-efficient Multilingual Learning
                        </span><br>
                       <span class="thisauthor">Simran Khanuja</span>, Srinivas Gowriraj, Lucio Dery, Graham Neubig<br>
                        <span class="conf"><a class="confshort" href="https://2024.naacl.org/">NAACL '24</a> |
                            Conference of the North American Chapter of the Association for Computational Linguistics</span><br>
                        <a class="tag" href="https://arxiv.org/abs/2311.06379" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://github.com/simran-khanuja/demux" target="_blank">code</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="assets/naacl-demux-slides.pptx" target="_blank">slides</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="assets/naacl-demux-poster.pdf" target="_blank">poster</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://youtu.be/YQv1v8EGBZA" target="_blank">video</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/demux.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">GlobalBench: A Benchmark for Global Progress in Natural Language Processing
                        </span><br>
                        Yueqi Song, Catherine Cui, <span class="thisauthor">Simran Khanuja</span>, Pengfei Liu, ..., Graham Neubig<br>
                        <span class="conf"><a class="confshort" href="https://2023.emnlp.org/">EMNLP '23</a> |
                            Conference on Empirical Methods in Natural Language Processing</span><br>
                        <a class="tag" href="https://arxiv.org/abs/2305.14716" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/globalbench.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Multi-lingual and Multi-cultural Figurative Language Understanding
                        </span><br>
                        Anubha Kabra<sup>*</sup>, Emmy Liu<sup>*</sup>, <span class="thisauthor">Simran Khanuja<sup>*</sup></span>, Alham Fikri Aji, Genta Indra Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, Graham Neubig<br>
                        <span class="conf"><a class="confshort" href="https://2023.aclweb.org/">ACL '23 Findings</a> |
                            Annual Meeting of the Association for Computational Linguistics</span><br>
                        <a class="tag" href="https://arxiv.org/abs/2305.16171" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://github.com/simran-khanuja/Multilingual-Fig-QA" target="_blank">code</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/figlang.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="badge badge-sp"> 🏆 Best Paper </span><br><span class="papertitle">FLEURS: Few-Shot Learning Evaluation of
                            Universal Representations of Speech
                        </span><br>
                        Alexis Conneau<sup>*</sup>, Min Ma<sup>*</sup>, <span class="thisauthor">Simran Khanuja<sup>*</sup></span>, Yu Zhang, Vera Axelrod, Siddharth Dalmia, Jason Riesa, Clara Rivera, Ankur Bapna <br>
                        <span class="conf"><a class="confshort" href="https://slt2022.org/">SLT '22</a> |
                            IEEE Spoken Language Technology Workshop</span><br>

                        <a class="tag" href="assets/fleurs_slt.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/fleurs.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">MergeDistill : Merging Pre-trained Language Models using Distillation
                        </span><br>
                        <span class="thisauthor">Simran Khanuja</span>, Melvin Johnson, Partha Talukdar
                        <span class="conf"><a class="confshort" href="https://2021.aclweb.org/">Findings of ACL'21</a> |
                            Annual Conference of the Association for Computational Linguistics</span><br>

                        <a class="tag" href="https://arxiv.org/pdf/2106.02834.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/abs/2106.02834" target="_blank">abstract</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="assets/MergeDistill.pdf" target="_blank">slides</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/merge_distill.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="badge badge-sp"> 🗞️ Media Coverage</span><br><span class="papertitle">MuRIL : Multilingual Representations for Indian Languages</span><br>
                        <span class="thisauthor">Simran Khanuja</span>, Diksha Bansal, Sarvesh Mehtani, Savya Khosla,
                        Atreyee Dey, Balaji Gopalan, Dilip Kumar Margam, Pooja Aggarwal, Rajiv Teja Nagipogu, Shachi
                        Dave, Shruti Gupta, Subhash Chandra Bose Gali, Vish Subramanian, Partha Talukdar<br>
                        <a class="tag" href="https://tfhub.dev/google/MuRIL/1" target="_blank">tfhub</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://huggingface.co/google/muril-base-cased"
                            target="_blank">huggingface</a><span class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/pdf/2103.10730.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/abs/2103.10730" target="_blank">abstract</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/muril.bib" target="_blank">cite</a><br>
                        Coverage: <a class="tag"
                        href="https://economictimes.indiatimes.com/tech/technology/google-aims-to-help-researchers-startups-better-understand-indian-languages/articleshow/79773091.cms"
                        target="_blank">Economic Times</a><span class="tagsep">|</span>
                    <a class="tag"
                        href="https://www.newindianexpress.com/opinions/2020/dec/24/making-use-of-the-language-landscape-diversity-2240471.html"
                        target="_blank">Indian Express</a><span class="tagsep">|</span>
                    <a class="tag" href="https://india.googleblog.com/2020/12/l10n-localisation-breaking-down.html"
                        target="_blank">Google AI Blog</a> 
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">GLUECoS: An Evaluation Benchmark for Code-Switched NLP</span><br>
                        <span class="thisauthor">Simran Khanuja</span>, Sandipan Dandapat, Anirudh Srinivasan, Sunayana
                        Sitaram, Monojit Choudhury <br>
                        <span class="conf"><a class="confshort" href="https://acl2020.org/">ACL'20</a> | Annual
                            Conference of the Association for Computational Linguistics</span><br>
                        <a class="tag" href="https://arxiv.org/pdf/2004.12376.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/abs/2004.12376" target="_blank">abstract</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://github.com/microsoft/GLUECoS" target="_blank">code</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://microsoft.github.io/GLUECoS/" target="_blank">website</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="assets/gluecos.pdf" target="_blank">slides</a><span class="tagsep">|</span>
                        <a class="tag"
                            href="https://slideslive.com/38928983/gluecos-an-evaluation-benchmark-for-codeswitched-nlp"
                            target="_blank">video</a><span class="tagsep">|</span>
                        <a class="tag" href="cites/gluecos.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">A New Dataset for Natural Language Inference from Code-mixed
                            Conversations</span><br>
                        <span class="thisauthor">Simran Khanuja</span>, Sandipan Dandapat, Sunayana Sitaram, Monojit
                        Choudhury <br>
                        <span class="conf"><a class="confshort"
                                href="https://code-switching.github.io/2020/wi.html">CALCS, LREC'20</a> | International
                            Conference on Language Resources and Evaluation</span><br>
                        <a class="tag" href="https://arxiv.org/pdf/2004.05051.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/abs/2004.05051" target="_blank">abstract</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="http://aka.ms/codemixedNLI" target="_blank">data</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/lrec.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Unsung Challenges of Building and Deploying Language Technologies for
                            Low Resource Language Communities</span><br>
                        Pratik Joshi, Christain Barnes, Sebastin Santy, <span class="thisauthor">Simran Khanuja</span>,
                        Sanket Shah, Anirudh Srinivasan, Satwik Bhattamishra, Sunayana Sitaram, Monojit Choudhury,
                        Kalika Bali <br>
                        <span class="conf"><a class="confshort"
                                href="https://blogs.iiit.ac.in/monthly_news/international-conference-on-natural-language-processing-icon-2019-2/">ICON'19</a>
                            | International Conference on Natural Language Processing </span><br>
                        <a class="tag" href="https://arxiv.org/pdf/2004.12376.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://arxiv.org/abs/2004.12376" target="_blank">abstract</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="cites/icon.bib" target="_blank">cite</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Dependency Parser for Bengali-English Code-Mixed Data enhanced with a
                            Synthetic Treebank</span><br>
                        Urmi Ghosh, <span class="thisauthor">Simran Khanuja</span>, Dipti Misra Sharma <br>
                        <span class="conf"><a class="confshort"
                                href="https://syntaxfest.github.io/syntaxfest19/tlt2019/tlt2019.html#:~:text=TLT%202019%20%2D%20Paris%20%2D%20August%2028,anglophone%22%20of%20the%20Sorbonne%20Nouvelle.">TLT,
                                SyntaxFest 2019</a></span><br>

                        <a class="tag" href="https://www.aclweb.org/anthology/W19-7810.pdf" target="_blank">pdf</a><span
                            class="tagsep">|</span>
                        <a class="tag" href="https://www.aclweb.org/anthology/W19-7810/"
                            target="_blank">abstract</a><span class="tagsep">|</span>
                        <a class="tag"
                            href="https://github.com/simran-khanuja/IIITH-Summer2018/tree/master/Code-Mixed%20Data/Code-Mixing"
                            target="_blank">code</a><span class="tagsep">|</span>
                        <a class="tag" href="cites/tlt.bib" target="_blank">cite</a>
                    </p>
                </div>
                <p class="header pt-5">Talks and Interviews</p>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Decode With Google 2022</span><br>
                        <a class="tag" href="https://hopin.com/events/decode-with-google#speakers" target="_blank">Speaker List</a><span
                            class="tagsep">|</span>
                        <span class="conf"><a class="confshort"
                                href="https://app.hopin.com/events/decode-with-google/replay/TGl2ZXN0cmVhbVJlY29yZGluZzo3NTg4MjI=">Talk (2:28:00 onwards)</a>, (registration required)</span>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">An Introduction to (Modern) TensorFlow</span><br>
                        <span class="thisauthor">Simran Khanuja</span>, Ameya Daigavane <br>
                        <span class="conf"><a class="confshort"
                                href="http://cvit.iiit.ac.in/summerschool2021/program.php">CVIT Summer School</a>, IIIT
                            Hyderabad</span><br>
                        <a class="tag" href="assets/TensorFlowTutorial.pdf" target="_blank">slides</a>
                    </p>
                </div>
                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Journey into Research</a></span><br>
                        <span class="conf"><a class="confshort" href="https://guidancebphc.wixsite.com/myblog">Rotaract
                                Club</a>, BITS Hyderabad</span><br>
                        <a class="tag"
                            href="https://guidancebphc.wixsite.com/myblog/post/simran-khanuja-pre-doctoral-researcher-at-google-research"
                            target="_blank">interview</a>
                    </p>
                </div>

                <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="badge badge-sp"> 🏆 National Rank 1 </span><br><span class="papertitle">ICSE National Topper</a></span><br>

                        <span class="conf">St. Mary's School, Pune</span><br>
                        Media Coverage: <a class="tag"
                            href="https://punemirror.indiatimes.com/pune/cover-story/a-musical-mantra-a-sporting-key/articleshow/31357611.cms"
                            target="_blank">India Times</a><span class="tagsep">|</span>
                        <a class="tag"
                            href="https://timesofindia.indiatimes.com/city/pune/100-result-in-pune-icse-schools/articleshow/20116779.cms"
                            target="_blank">Times of India</a><span class="tagsep">|</span>
                        <a class="tag"
                            href="https://indianexpress.com/article/cities/pune/high-fliers-icing-on-cake-as-most-city-schools-score-cent-per-cent/"
                            target="_blank">Indian Express</a><span class="tagsep">
                    </p>
                </div>
            </div>

            <!--                 <div class="row text-center py-4">
                    <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-3" src="images/google.png">
                        <div class="institution">Google Research</div>
                        <div class="years">2020-Present</div>
                    </div>
                    <div class="mx-auto mt-2 ml-3">
                        <img class="img-fluid instilogo p-2" src="images/microsoft_research_logo.jpg">
                        <div class="institution">Microsoft Research</div>
                        <div class="years">2019 - 2020</div>
                    </div>
                    <div class="mx-auto mt-2 ml-3">
                        <img class="img-fluid instilogo p-3" src="images/bitspilani.png">
                        <div class="institution">BITS Pilani</div>
                        <div class="years">2015 - 2020</div>
                    </div>
                    <div class="mx-auto mt-2 ml-3">
                        <img class="img-fluid instilogo p-2" src="images/iiith.png">
                        <div class="institution">IIIT Hyderabad</div>
                        <div class="years">Summer 2018</div>
                    </div>
                    <div class="mx-auto mt-2 ml-3">
                        <img class="img-fluid instilogo p-3" src="images/liveweaver.png">
                        <div class="institution">Liveweaver</div>
                        <div class="years">Summer 2017</div>
                    </div>
                    
                </div>  -->

        </div>

    </div>
    </div>

    <footer>
        <div class="text-center medium mt-2"><a href="https://github.com/SebastinSanty/minimal-research-theme">Website
                template</a> | <a href="https://github.com/SebastinSanty/Just-Another-Research-CV">CV template</a></div>
        <br>
    </footer>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
        integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
        integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
        crossorigin="anonymous"></script>
    <script src="assets/style-2.js"></script>
</body>
<style>
</style>

</html>